---
title: "Axes of Variation"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    source_code: embed
    theme: flatly
    navbar:
      - { title: "scPipeline", href: "https://github.com/NMikolajewicz/scPipeline" }
      - { title: "scMiko", href: "https://github.com/NMikolajewicz/scMiko" }  
editor_options: 
  chunk_output_type: inline
knit: (function(inputFile, encoding) {
    rmarkdown::render(input = inputFile,
      encoding = encoding,
      output_file = if (exists("user")){paste0(
        xfun::sans_ext(inputFile), '_',user, "_", 
        paste0(format(Sys.time(), "%d_%b_"), gsub(" ", "_", gsub(":", "_", format(Sys.time(), "%X"))), format(Sys.time(), "_%Y")), '.html'
      )} else {paste0(xfun::sans_ext(inputFile), '_',"Guest", "_", 
      paste0(format(Sys.time(), "%d_%b_"), gsub(" ", "_", gsub(":", "_", format(Sys.time(), "%X"))), format(Sys.time(), "_%Y")), '.html')},
      output_dir = if (exists("data.path")) paste0(data.path, "/HTML_Reports") else NULL
    )
  })
---



```{r setup, include=FALSE}

# clear global enviroment
rm(list = setdiff(ls(), c("data.path", "user")))
invisible({gc()})

# initiate timer
start.time <- proc.time()

# List of packages to load
packages2load <- c("Seurat", "scMiko", "DT", "scales", "plyr", 
                   "dplyr", "tidyr", "RColorBrewer", "ggplot2", 
                   "flexdashboard", "future", "BiocParallel",
                   "parallel", "doParallel", "foreach", "iterators")

# "lme4", "variancePartition",
# load packages
suppressMessages(suppressWarnings(lapply(packages2load, library, character.only = TRUE, quietly = T)))

```



```{r analysis specifications}

# parameter specification
parameter.list <- list(
  # input.file = "M01_NM2_R1_test_300720.Rdata",
  # input.file = "R404_M02_NM2_celsius_renca_rpca_filtered_220321.Rdata",
  input.file = "R443_M02_NM2_p9_GBM_PR_integrated_SCTrerun_110521.Rdata",
  # input.file = "R304_M27_NM2_M02_BC2_allGBM_tumorStringent_tier1_251120.Rdata",
  # input.file = "branch_p12_meso_020521.rds",
  # input.file = 	"R65_M01_NM2_p11_neural_DIV7_270820.Rdata",
  # input.file = "R416_M02_NM2_p12_meso_integrated_170421.Rdata",
  cluster.resolution = 0.5,
  subsample_factor = 1,
  pca.cum.var.explained = 0.9, 
  pca.reduction.name = "pca", 
  subset.data = NA,
  gsea.n.workers = 6,
  pathway.db = "Bader" #Bader, GO

)


filter.parameters <- list(
  include = NULL,
  omit = NULL
)


# print inline
print.inline <- FALSE # OPTIONAL; TRUE/FALSE

# save PDF
save.pdf <- update.log <- T


```



```{r load data, warning = FALSE}

message("Importing data...")

set.seed(1023)

# Specify data directories
dir.preprocessed <- "Preprocessed_Datasets/"

if (!exists("data.path") & !exists("user")) {
  stop("data.path and user variables do not exist in global enviroment. Ensure that these are specified in .Rprofile. If specified, try restarting Rstudio.")
}

# load query dataset
input.file <- parameter.list$input.file
if ((!grepl(".Rdata|.RData", input.file)) & !(grepl(".rds", input.file))) input.file <- paste0(input.file, ".Rdata")

if (grepl(".Rdata|.RData", input.file)){
  load(paste(data.path, dir.preprocessed, input.file, sep = ""));
} else if (grepl(".rds", input.file)) {
  so <- readRDS(paste(data.path, dir.preprocessed, input.file, sep = ""))
}


if (!exists("gNames.list")) gNames.list <- prepGeneList(so, objects())

t2d <- c("ica", "tsne", "nmf", "corr", "gsva", "deg", "integration.anchors")

# prep seurat object
prep.list <- prepSeurat2(so, e2s = gNames.list, 
                         species =  parameter.list$species, resolution= parameter.list$cluster.resolution, 
                         subset.data = parameter.list$subset.data, 
                         subsample = parameter.list$subsample_factor, M00_subgroup.path = "M00_subgroups.csv",
                         terms2drop = t2d, rmv.pattern = "so", keep.default.assay.only = T)

# unpack results
if (exists("so")) try({rm(so)}, silent = T)
so.query <- prep.list$so
current.assay <- prep.list$assay
n.cells <- prep.list$n.cell
rm(prep.list);
invisible({gc()})

# check that reduction is available
if (!(parameter.list$pca.reduction.name %in% names(so.query@reductions))) stop("'", parameter.list$pca.reduction.name, "' is not a valid reduction object. Perform PCA using 'RunPCA()' prior to running current module.")

# determine species representation in seurat object
parameter.list$species <- detectSpecies(so.query)

```

```{r filter clusters}

if (exists("filter.parameters")){
  so.query <- clusterFilter(so.query, include = filter.parameters$include, omit = filter.parameters$omit)
  
  # TODO ensure that refactorization does not renumber values
  so.query@meta.data[["seurat_clusters"]] <- factor(as.character(so.query@meta.data[["seurat_clusters"]]))
  Idents(object = so.query) <- 'seurat_clusters'
}

```

```{r analysis log, include = FALSE, }

message("Updating analysis log...")

# Initiate and fill analysis Log
df.log <- initiateLog("38, Axis of Variation")
df.log <- addLogEntry("PDF saved", save.pdf, df.log, "save.pdf")
df.log <- addLogEntry("Update Central Log", update.log, df.log, "update.log")
df.log <- addLogEntry("Print Inline", print.inline, df.log, "print.inline")

df.log <- addLogEntry("Input file", parameter.list$input.file, df.log, "input.file")
df.log <- addLogEntry("Cluster resolution", parameter.list$cluster.resolution, df.log, "cluster.resolution")
df.log <- addLogEntry("Subsample factor", parameter.list$subsample_factor, df.log, "subsample_factor")
df.log <- addLogEntry("data subset", parameter.list$subset.data, df.log, "subset.data")
df.log <- addLogEntry("species", parameter.list$species, df.log, "species")

df.log <- addLogEntry("Cumulative variance explained threshold", parameter.list$pca.cum.var.explained, df.log, "pca.cum.var.explained")
df.log <- addLogEntry("PCA reduction name", parameter.list$pca.reduction.name, df.log, "pca.reduction.name")

df.log <- addLogEntry("GSEA, n workers", parameter.list$gsea.n.workers, df.log, "gsea.n.workers")
df.log <- addLogEntry("GSEA, pathway database", parameter.list$pathway.db, df.log, "pathway.db")

```


```{r get past module logs, include = FALSE}
# determine prior log history
cur.env <- objects()
module.logs <- cur.env[grep("^df.log_Module",cur.env)]

```

```{r recode barcodes, warning = FALSE}


if (exists("barcode.list") && (length(barcode.list) > 0)){

df.meta <- so.query@meta.data

# relabel barcodes
bc.list <-barcode.list

df.meta$bc <- NA
for (i in 1:length(bc.list)){
  
  pattern <- bc.list[[i]]
  pattern.replace <- names(bc.list)[i]
  df.meta$bc[grepl(pattern, df.meta$Barcode)] <- pattern.replace
}

so.query@meta.data <- df.meta
  
} else {
  
  
  u.bc <- unique(so.query@meta.data[["Barcode"]])
  bc.list <- list()
  for (i in 1:length(u.bc)){
    bc.list[[i]] <- u.bc[i]
  }
  names(bc.list) <- u.bc
so.query@meta.data[["bc"]] <- so.query@meta.data[["Barcode"]]
}

```


```{r scree plot, fig.width=10, fig.height=5}


message("Generating scree plots...")

df.pca <- propVarPCA(so = so.query, reduction.name = parameter.list$pca.reduction.name)

pca.var.exp <- parameter.list$pca.cum.var.explained
which.pca <- df.pca$pc.id[df.pca$pc.cum_sum > pca.var.exp][1]

plt.scree2 <- df.pca %>% 
  ggplot(aes(x = pc.id, y = pc.cum_sum)) + 
  geom_point() + 
  labs(x = "PC", y = "Cumulative Variance Explained",  title = "", subtitle = paste0((100*pca.var.exp) , "% variance explained by ", which.pca, " PCs")) + 
   theme_miko() + 
  geom_vline(xintercept = which.pca, linetype = "dashed", color = "tomato") + 
  geom_hline(yintercept = pca.var.exp, linetype = "dashed", color = "tomato")


plt.scree1 <- df.pca %>% 
  ggplot(aes(x = pc.id, y = pc.prop_var)) + 
  geom_point() + 
  labs(x = "PC", y = "Proportion of Variance Explained", title = "Scree Plot", subtitle = "Proportion of variance explained by each prinicipal component") + 
   theme_miko() 


plt.scree <- cowplot::plot_grid(plt.scree1, plt.scree2, ncol = 2)

if (print.inline){
  print(plt.scree)
}

message(paste0((100*pca.var.exp) , "% variance explained by ", which.pca, " prinicipal components"))

```


```{r GSEA enrichment}

message("Running GSEA enrichment using genes ranked by PC loading...")

gsea.n.workers <- parameter.list$gsea.n.workers

  df.pca.loading <- as.data.frame(so.query@reductions[[parameter.list$pca.reduction.name]]@feature.loadings)
  df.load.list <- as.list(df.pca.loading)
  df.load.list <- df.load.list[1:which.pca]
  if (gsea.n.workers > length(df.load.list)) gsea.n.workers <- length(df.load.list)

if (gsea.n.workers > 1){
  
  cl <- parallel::makeCluster(gsea.n.workers)
  doParallel::registerDoParallel(cl)
  
  parallel::clusterExport(cl = cl, varlist = c("df.load.list", "df.pca.loading", "parameter.list", "runGSEA",  
                                "theme", "element_blank", "element_text", "xlab", "ylab", "labs", "geom_vline", 
                      "mapvalues", "%>%", "bind_rows", "ggplot", "aes", "geom_segment", "geom_point", "theme_bw"),  envir = knitr::knit_global())
  
  gsea.res <- parallel::parLapply(cl = cl, X = df.load.list, function(x){ 
    runGSEA(gene = rownames(df.pca.loading), value = unlist(x), species = parameter.list$species, db = parameter.list$pathway.db)
  })
  
  # stop workers
  parallel::stopCluster(cl)
  
} else {

  
  gsea.res <- pbapply::pblapply(df.load.list, function(x){ 
    runGSEA(gene = rownames(df.pca.loading), value = unlist(x), species = parameter.list$species, db = parameter.list$pathway.db)
  })
  
}

message("Extracting GSEA summary plots...")
gsea.plots <- pbapply::pblapply(gsea.res, function(x) x$plt.gsea)
names(gsea.plots) <- gsub("_", "", names(gsea.plots))


```


```{r project reductions, fig.width=10, fig.height=5}

message("Projecting PCA loadings onto cellular UMAP...")
plt.pca.list <- projectReduction(object = so.query, reduction =  parameter.list$pca.reduction.name, 
                                 show.n.features = 40, size = autoPointSize(ncol(so.query)),
                                 pca.min.var.exp = 0, pca.cum.pca.thresh = parameter.list$pca.cum.var.explained, rel.width = c(2,1))

```




```{r generate summary plots, fig.width=20, fig.height=7.5}

message("Generating summary plots...")

plt.summary.list <- pbapply::pblapply(seq_along(plt.pca.list), function(red.plot, gsea.plot, n, i){
  cowplot::plot_grid(red.plot[[n[i]]], gsea.plot[[n[i]]], nrow = 1, rel_widths = c(2, 1.5))
}, 
red.plot=plt.pca.list, gsea.plot =  gsea.plots, n=names(plt.pca.list))

names(plt.summary.list) <- names(plt.pca.list)

```



```{r central log}

# update central log
run.id <- NULL
if (!exists("user")) user <- "guest"

clog.update.success <- F
try({
  run.id <-  updateCentralLog(Module = "M38", input.data = input.file, input.subset = NA, pdf.flag = save.pdf)
  clog.update.success <-  T
}, silent = F)
if (is.null(run.id))  {
  warning("Central log update was unsuccessful :(\n")
  run.id <- paste("M38_", user, "_r", paste0(format(Sys.time(), '%s')), sep = "", collapse = "")
}

```


```{r setup output directories}

# # output path
if (!exists("data.path")) data.path = ""
output.path <- paste0(data.path, "Module_Outputs/", paste0(run.id,"_",format(Sys.time(), '%d%m%y'), "/"))

# create output directories
dir.create(output.path)
dir.create(paste0(output.path, "Tables/"))
if (save.pdf) dir.create(paste0(output.path, "PDF/"))

```



Axes of Variation
=====================================



Sidebar {.sidebar}
-------------------------------------

**Axes of variation**

**Description**: Identification and annotation of axes of variation in single cell expression. 

**Method**: Transcriptomic expression matrix is dimensionally-reduced using principal component analysis (PCA) and the top PCA explaining the principal axes of variation are visualized on a UMAP (cell-loadings). Genes ranked by PC loading are enriched using gene-set enrichment analysis (GSEA) to functionally annotate each axis of variation. 



Row {data-height=400}
-------------------------------------
    
### Sample Overview
    
```{r, fig.width=15, fig.height=5}

plt.umap.final <- cluster.UMAP(so.query) + theme_miko(legend = F) + labs(title = "UMAP", subtitle = paste0(ncol(so.query), " cells | ", ulength(so.query$seurat_clusters), " clusters"))
plt.overview <- cowplot::plot_grid(plt.umap.final, plt.scree1, plt.scree2, ncol = 3)
print(plt.overview)

```


   
Row {.tabset .tabset-fade data-height=600}
-------------------------------------
   

```{r PCA reduction plots}

out <- lapply(seq_along(plt.summary.list), function(i) {
  
  s1 <- names(plt.summary.list)[i]
  s2 <- paste0("plt.summary.list[[", i, "]]")
  
  a1 <- knitr::knit_expand(text = sprintf("### %s\n", s1))  # tab header
  a2 <- knitr::knit_expand(text = sprintf("\n```{r %s, message=FALSE, warning=FALSE, fig.width = 15, fig.height=5}",  #fig.width = 8, fig.height=8, 
                                          paste("pc_", i, sep = "")))
  a3 <- knitr::knit_expand(text = sprintf("\n %s", s2)) 
  a4 <- knitr::knit_expand(text = "\n```\n") # end r chunk
  
  paste(a1, a2, a3, a4, collapse = '\n') # collapse together all lines with newline separator
  
})

```

`r paste(knitr::knit(text = paste(out, collapse = '\n')))`
 
 
 
```{r finalize log}

# Update analysis log
n.cells.analyzed <- ncol(so.query)
df.log <- addLogEntry("Number of cells analyzed", n.cells.analyzed, df.log, "n.cells.analyzed")
df.log <- addLogEntry("Seurat Assay", DefaultAssay(so.query), df.log, "DefaultAssay(so.query)")

# Run time
end.time <- proc.time()
elapsed.time <- round((end.time - start.time)[[3]], 2)
df.log <- addLogEntry("Run Time (s)", elapsed.time, df.log, "elapsed.time")

df.log <- addLogEntry("Run Identifier", run.id, df.log, "run.id")
df.log <- addLogEntry("User", user, df.log, "user")
df.log <- addLogEntry("Central Log Updated", clog.update.success, df.log, "clog.update.success")

df.log_Module_38 <- df.log

```



```{r ph10,  echo = FALSE, eval = TRUE}

out1 <- lapply(seq_along(module.logs), function(i) {
  
  module.n <- as.numeric(gsub("[^\\d]+", "", module.logs[i], perl=TRUE))
  
  a1 <- knitr::knit_expand(text = sprintf("\nLog (Module %s)", paste(module.n)))
  a2 <- knitr::knit_expand(text = "\n=====================================")
  a3 <- knitr::knit_expand(text = sprintf("\n```{r %s}", paste("mod_", i, sep = ""))) # start r chunk
  a4<- knitr::knit_expand(text = sprintf("\nknitr::kable(%s)",module.logs[i])) 
  a5 <- knitr::knit_expand(text = "\n```\n") # end r chunk
  
  paste(a1, a2, a3, a4, a5, collapse = '\n') # collapse together all lines with newline separator
})


```

`r paste(knitr::knit(text = paste(out1, collapse = '\n')))`

 
Log (Module 38)
===================================== 

```{r table.log_current}
knitr::kable(df.log_Module_38)
```

```{r save analysis log as csv}

try({
  write.csv(df.log_Module_38, file = paste0(output.path, "Tables/", "analysisLog.csv"), 
    row.names = F)  
}, silent = T)

```


System Info
=====================================

```{r}

pander::pander(sessionInfo())

```

