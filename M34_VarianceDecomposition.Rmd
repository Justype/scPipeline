---
title: "Variance Decomposition"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
editor_options: 
  chunk_output_type: inline
knit: (function(inputFile, encoding) {
    rmarkdown::render(input = inputFile,
      encoding = encoding,
      output_file = if (exists("user")){paste0(
        xfun::sans_ext(inputFile), '_',user, "_", format(Sys.Date(), "%d%m%y"), '.html'
      )} else {paste0(xfun::sans_ext(inputFile), '_',"Guest", "_", format(Sys.Date(), "%d%m%y"), '.html')},
      output_dir = if (exists("data.path")) paste0(data.path, "/HTML_Reports") else NULL
    )
  })
---



```{r setup, include=FALSE}

# clear global enviroment
rm(list = setdiff(ls(), c("data.path", "user")))
invisible({gc()})

# initiate timer
start.time <- proc.time()

# List of packages to load
packages2load <- c("Seurat", "scMiko", "DT", "lme4", "variancePartition",
                   "dplyr", "tidyr", "RColorBrewer", "ggplot2", 
                   "flexdashboard", "future", "BiocParallel",
                   "parallel", "doParallel", "foreach")

# load packages
invisible(lapply(packages2load, library, character.only = TRUE))

```



```{r analysis specifications}

# parameter specification

parameter.list <- list(
  # input.file = "R65_M01_NM2_p11_neural_DIV7_270820.Rdata",
  # input.file = "R71_M01_NM2_p10_CGR8_310820.Rdata",
  # input.file = "M01_NM2_R1_test_300720.Rdata",
  input.file = "R304_M27_NM2_M02_BC2_allGBM_tumorStringent_tier1_251120.Rdata",
  cluster.resolution = 1,
  subsample_factor = 0.5,
  subset.data = NA,
  species = "Mm",
  covariates = c( "cluster", "percent.mt", "batch", "cycle", "seq.coverage"), # specify by new name if recoding/relabeling
  interactions = c("batch:cluster"),
  # interactions = c(),
  pct.min = 0,
  use.variable.genes = T, # INCORPORATE THIS!
  n.workers.vd = 20 # workers for variance decomposition
)

# relabel list #################################################################
# list entries = old names; list names = new names
relabel.list <- list(
  barcode = "Barcode",
  cluster = "seurat_clusters",
  percent.mt = "percent.mt",
  batch = "bc",
  seq.coverage = "nCount_RNA",  # "nCount_SCT" or "nCount_RNA" depending on assay
  cycle = "Phase"
)

# recode list ##################################################################
# if recoding and relabeling, use new label from recoding as old label for relabeling. 
recode.list <- list(
  # bc = list( # new name
  #   Barcode = list( # old name
  #     WT = "WT",  # new entry = old entry
  #     C50 = "C50",
  #     C68 = "C68",
  #     C15 = "C15",
  #     C2 = "C2",
  #     C76  = "C76"
  #   )
  # )
  bc = list( # new name
    Barcode = list( # old name
      GL261 = "GL261",  # new entry = old entry
      CT2A = "CT2A"
    )
  )
)



# print inline
print.inline <- FALSE # OPTIONAL; TRUE/FALSE

# save PDF
save.pdf <- T
update.log <- T


```




```{r load data, warning = FALSE}

message("Importing data...\n")


# Specify data directories
dir.preprocessed <- "Preprocessed_Datasets/"

if (!exists("data.path") & !exists("user")) {
  stop("data.path and user variables do not exist in global enviroment. Ensure that these are specified in .Rprofile. If specified, try restarting Rstudio.")
}

# load query dataset
warning("Importing data...")
input.file <- parameter.list$input.file
if (!grepl(".Rdata|.RData", input.file)) input.file <- paste0(input.file, ".Rdata")
load(paste(data.path, dir.preprocessed, input.file, sep = ""));

if (!exists("gNames.list")) gNames.list <- prepGeneList(so, objects())

t2d <- c("ica", "tsne", "nmf", "corr", "gsva", "deg", "integration.anchors")

# prep seurat object
prep.list <- prepSeurat2(so, e2s = gNames.list, 
                         species =  parameter.list$species, resolution= parameter.list$cluster.resolution, 
                         subset.data = parameter.list$subset.data, 
                         subsample = parameter.list$subsample_factor, M00_subgroup.path = "M00_subgroups.csv",
                         terms2drop = t2d, rmv.pattern = "so", keep.default.assay.only = T)

# unpack results
if (exists("so")) try({rm(so)}, silent = T)
so.query <- prep.list$so
current.assay <- prep.list$assay
n.cells <- prep.list$n.cell
rm(prep.list);
invisible({gc()})


```


```{r analysis log, include = FALSE}

# Initiate and fill analysis Log
df.log <- initiateLog("34, Variance Decomposition")
df.log <- addLogEntry("PDF saved", save.pdf, df.log, "save.pdf")
df.log <- addLogEntry("Update Central Log", update.log, df.log, "update.log")
df.log <- addLogEntry("Print Inline", print.inline, df.log, "print.inline")

df.log <- addLogEntry("Input file", parameter.list$input.file, df.log, "input.file")
df.log <- addLogEntry("Cluster resolution", parameter.list$cluster.resolution, df.log, "cluster.resolution")
df.log <- addLogEntry("Subsample factor", parameter.list$subsample_factor, df.log, "subsample_factor")
df.log <- addLogEntry("data subset", parameter.list$subset.data, df.log, "subset.data")
df.log <- addLogEntry("species", parameter.list$species, df.log, "species")
df.log <- addLogEntry("covariates", parameter.list$covariates, df.log, "covariates")
df.log <- addLogEntry("interactions", parameter.list$interactions, df.log, "interactions")
df.log <- addLogEntry("minimal expressing fraction", parameter.list$pct.min, df.log, "pct.min")
df.log <- addLogEntry("Use variable genes", parameter.list$use.variable.genes, df.log, "use.variable.genes")
df.log <- addLogEntry("N workers", parameter.list$n.workers.vd, df.log, "n.workers.vd")

```


```{r get past module logs, include = FALSE}
# determine prior log history
cur.env <- objects()
module.logs <- cur.env[grep("^df.log_Module",cur.env)]

```


```{r recode barcodes}

df.meta <- so.query@meta.data

if (exists("recode.list") &&( length(recode.list) > 0)){
  
  for (k in 1:length(recode.list)){
    
    # relabel barcodes
    bc.list <-recode.list[[k]][[1]]
    field.name <- names(recode.list[[k]])
    
    df.meta$placeholder <- NA
    which.complete.all <- NULL
    for (i in 1:length(bc.list)){
      
      pattern <- bc.list[[i]]
      pattern.replace <- names(bc.list)[i]
      df.meta$placeholder[grepl(pattern, df.meta[ ,field.name])] <- pattern.replace
    }
    
    df.meta[ ,names(recode.list)[k]] <- df.meta$placeholder
    
    which.complete <- !is.na(df.meta[ ,names(recode.list)[k]])
    
    if (is.null(which.complete.all)){
      which.complete.all <- which.complete
    } else {
      which.complete <- which.complete.all |  which.complete
    }
    
  }
  
  so.query@meta.data <- df.meta
  
  # keep complete cases
  so.query <- so.query[, which.complete]
  
}



```

```{r relabel covariates}

if (exists("relabel.list") &&( length(relabel.list) > 0)){
  # get meta data
  df.meta <- so.query@meta.data
  # relabel
  for (i in 1:length(relabel.list)){
    new.label <- names(relabel.list)[i]
    old.label <- relabel.list[[i]]
    if (old.label %in% colnames(df.meta)){
      df.meta[ ,new.label] <-  df.meta[ ,old.label]
    }
  }
  # put meta data back
   so.query@meta.data <- df.meta
}

```


```{r specify model}

# get model covariates
if ("covariates" %in% names(parameter.list)){
  covariate.names <- parameter.list$covariates
} else {
  stop("Covariates specification is missing. ")
}

# get model interactions
if ("interactions" %in% names(parameter.list)){
  interaction.names <- parameter.list$interactions
} else {
  interaction.names <- c()
}


# check which.available
covariates.av <- covariate.names[covariate.names %in% colnames(df.meta)]

# check if interactions are available
df.interaction.pairs <- NULL
if (length(interaction.names) > 0){
  for (i in 1:length(interaction.names)){
    cov.int <- c(unlist(strsplit(interaction.names[i], ":")))
   if(all(cov.int %in% covariates.av)){
     df.interaction.pairs <- bind_rows(
       data.frame(v1 = cov.int[1], v2 = cov.int[2])
     )
   }
  }
}

if (!is.null(df.interaction.pairs)){
  do.interaction <- T
} else {
  do.interaction <- F
}


append.term <- function(func, term){
  if (length(func) == 0){
    func <- paste0("~ ",term)
  } else {
    func <- paste0(func, " + ", term)
  }
  return(func)
}

# variable types
df.var.type <- NULL
form <- c()
for (i in 1:length(covariates.av)){
  
 var.current <-  df.meta[ ,covariates.av[i]]
  if ((is.numeric(var.current)) | (is.integer(var.current))){
    df.var.type <- bind_rows(df.var.type, 
                             data.frame(
                               variable = covariates.av[i],
                               type = "continuous"
                             ))
    
    form <- append.term(form, covariates.av[i])
  } else if ((is.character(var.current)) | (is.factor(var.current))){
        df.var.type <- bind_rows(df.var.type, 
                             data.frame(
                               variable = covariates.av[i],
                               type = "categorical"
                             ))
        form <- append.term(form, paste0("(1|", covariates.av[i], ")"))
  }
 
  
}

# append interaction terms
for (i in 1:nrow(df.interaction.pairs)){
  
 term.current <-  paste0(df.interaction.pairs[i,1], ":", df.interaction.pairs[i,2])
  form <- append.term(form,  paste0("(1|", term.current, ")"))

}

# specify model formula
form2 <- as.formula(form)

# get covariate data
df.meta <- so.query@meta.data
df.meta.sub <- df.meta[ ,covariates.av]

```


```{r UMAPs for each parameter}

plt.umap.list <- list()
for (i in 1:nrow(df.var.type)){
  
  
  field.name <-df.var.type$variable[i]
  var.type <- df.var.type$type[i]
  
  if (var.type == "categorical"){
   plt.umap.list[[field.name]] <-  cluster.UMAP(so.query, group.by = field.name) + theme_miko(legend = T) + 
      labs(title = field.name, subtitle = "UMAP")
  } else if (var.type == "continuous"){
   plt.umap.list[[field.name]] <-  FeaturePlot(so.query, feature = field.name, cols = c("lightgrey", "darkgreen")) + theme_miko(legend = T) + 
      labs(title = field.name, subtitle = "UMAP") + 
     xlab("UMAP 1") + ylab("UMAP 2")
  }

}


```


```{r iterators}

exprIter = function( exprObj, weights, useWeights = TRUE, scale=TRUE, iterCount = "icount"){

	n_features = nrow(exprObj)

	if( iterCount == 'icount2'){
		xit <- icount2( n_features )
	}else{
		xit <- icount( n_features )
	}

    nextEl <- function() {
    	j <- nextElem(xit)

    	if( is.null(j) || j > n_features){
    		res = NULL
    	}else{
	    	if( useWeights && !is.null(weights) ){    		
				# scale weights to have mean of 1, otherwise it affects the residual variance too much
	    		if(scale){
	    			w = weights[j,] /  mean(weights[j,])
	    		}else{
	    			w = weights[j,]
	    		}
	    	}else{
	    		w = NULL		
			}

	       	res = list(E = exprObj[j,], weights = w, n_iter = j, max_iter = n_features)
	     }
	     res
    }
    it <- list(nextElem = nextEl)
    class(it) <- c("abstractiter", "iter")
    it
}

```

```{r part 1 helper function}

fitVarPartModel2 <- function( exprObj, formula, data){ 
  
  # exprObj = e.mat.sub[ ,subsample.ind]
  # formula = form
  # data = df.meta.sub[ subsample.ind,]
  REML=FALSE
  useWeights=TRUE
  weightsMatrix=NULL
  showWarnings=TRUE
  fxn=identity
  colinearityCutoff=.999
  control = lme4::lmerControl(calc.derivs=FALSE, check.rankX="stop.deficient" )

  formula = stats::as.formula( formula )
  
  # only retain columns used in the formula
  data = data[, colnames(data) %in% unique(all.vars(formula)), drop=FALSE]
  
  # check dimensions of reponse and covariates
  if( ncol(exprObj) != nrow(data) ){		
    stop( "the number of samples in exprObj (i.e. cols) must be the same as in data (i.e rows)" )
  }
  
  # check if all genes have variance
  if( ! is(exprObj, "sparseMatrix")){
    # check if values are NA
    countNA = sum(is.nan(exprObj)) + sum(!is.finite(exprObj))
    if( countNA > 0 ){
      stop("There are ", countNA, " NA/NaN/Inf values in exprObj\nMissing data is not allowed")
    }
    
    rv = apply( exprObj, 1, var)
  }else{
    rv = c()
    for( i in seq_len(nrow(exprObj)) ){
      rv[i] = var( exprObj[i,])
    }
  }
  if( any( rv == 0) ){
    idx = which(rv == 0)
    stop(paste("Response variable", idx[1], 'has a variance of 0'))
  }
  
  # if weightsMatrix is not specified, set useWeights to FALSE
  if( useWeights && is.null(weightsMatrix) ){
    # warning("useWeights was ignored: no weightsMatrix was specified")
    useWeights = FALSE
  }
  
  # if useWeights, and (weights and expression are the same size)
  if( useWeights && !identical( dim(exprObj), dim(weightsMatrix)) ){
    stop( "exprObj and weightsMatrix must be the same dimensions" )
  }
  
  # If samples names in exprObj (i.e. columns) don't match those in data (i.e. rows)
  if( ! identical(colnames(exprObj), rownames(data)) ){
    warning( "Sample names of responses (i.e. columns of exprObj) do not match\nsample names of metadata (i.e. rows of data).  Recommend consistent\nnames so downstream results are labeled consistently." )
  }
  
  form = paste( "responsePlaceholder$E", paste(as.character( formula), collapse=''))
  
  responsePlaceholder = nextElem(exprIter(exprObj, weightsMatrix, useWeights))
  possibleError <- tryCatch( lmer( eval(parse(text=form)), data=data,...,control=control ), error = function(e) e)
  
  # detect error when variable in formula does not exist
  if( inherits(possibleError, "error") ){
    err = grep("object '.*' not found", possibleError$message)
    if( length(err) > 0 ){
      stop("Variable in formula is not found: ", gsub("object '(.*)' not found", "\\1", possibleError$message) )
    }
  }
  
  # fit first model to initialize other model fits - this make the other models converge faster
  responsePlaceholder = nextElem(exprIter(exprObj, weightsMatrix, useWeights))
  fitInit <- lmer( eval(parse(text=form)), data=data, REML=REML, control=control )
  
  # specify gene explicitly in data 
  data2 = data.frame(data, expr=responsePlaceholder$E, check.names=FALSE)
  form = paste( "expr", paste(as.character( formula), collapse=''))
  
  input.data <- list(
    E = exprObj,
    weights = matrix(data = 1, nrow = nrow(exprObj), ncol = ncol(exprObj))
  )
  
  return(list(
    input.data = input.data,
    data2 = data2,
    form =  form,
    REML =  REML,
    theta =  fitInit@theta,
    fxn = fxn,
    control = control,
    na.action=stats::na.exclude
  ))	
}

```

```{r part 2 helper function}
extractVarPart2 <- function( modelList, showWarnings=TRUE,... ){

	# get results from first model to enumerate all variables present
	singleResult = calcVarPart( modelList[[1]], showWarnings=showWarnings,... )

	# for each model fit, get R^2 values
	entry <- 1
	varPart <- lapply( modelList, function( entry ) 
		calcVarPart( entry, showWarnings=showWarnings,... )
	)

	varPartMat <- data.frame(matrix(unlist(varPart), nrow=length(varPart), byrow=TRUE))
	colnames(varPartMat) <- names(varPart[[1]])
	rownames(varPartMat) <- names(modelList)

	modelType = ifelse(class(modelList[[1]])[1] == "lm", "anova", "linear mixed model")

	 new("varPartResults", varPartMat, type=modelType, method="Variance explained (%)")

}

```


```{r prep expression data}



# prep expression matrix
e.mat <- so.query@assays[[DefaultAssay(so.query)]]@data
p.mat <- e.mat > 0
p.exp <- rowSums(p.mat)/ncol(p.mat)
which.gene <- which(p.exp > parameter.list$pct.min)
e.mat.sub <- as.matrix(e.mat[which.gene, ])

# use variable genes
if ((length(so.query@assays[[DefaultAssay(so.query)]]@var.features) > 0) & (parameter.list$use.variable.genes)){
  var.genes <- so.query@assays[[DefaultAssay(so.query)]]@var.features
  which.genes.match <- rownames(e.mat.sub) %in% var.genes
  if (sum(which.genes.match) > 0){
    e.mat.sub <- e.mat.sub[which.genes.match, ]
  }
}

# final input data
# subsample.ind <- sample(seq(1, ncol(e.mat.sub)), round(0.1 * ncol(e.mat.sub)))
# e.mat.sub2 <- e.mat.sub[ ,subsample.ind]
# df.meta.sub2 <- df.meta.sub[subsample.ind ,]
e.mat.sub2 <- e.mat.sub
df.meta.sub2 <- df.meta.sub

# get model parameter list
par.list <- fitVarPartModel2( exprObj = e.mat.sub2, formula = form2, data = df.meta.sub2)


```




```{r perform variance decomposition}

# initiate clusters
cl <- parallel::makeCluster(parameter.list$n.workers.vd)
doParallel::registerDoParallel(cl)

# determine chunk size
chunk.size <- ceiling(nrow(par.list$input.data$E) / 19)
               fxn <- par.list$fxn       
chunk.start <- seq(1, 19*chunk.size, by = chunk.size)

res <- foreach(j = 1:(length(chunk.start)-1), .packages = c("lme4"))  %dopar% {
  
  seq.range <- (chunk.start[j]:(chunk.start[j+1]-1))
  if (max(seq.range) > nrow(par.list$input.data$weights)) seq.range <- (chunk.start[j]: nrow(par.list$input.data$weights))
  E.cur <- par.list$input.data$E[seq.range,]
  W.cur <- par.list$input.data$weights[seq.range,]
  data3 <- par.list$data2
  res.cur <- list()
  which.gene <- c()
  for (k in 1:nrow(E.cur) ){
    
    try({
      data3$expr <- E.cur[k,]
      res.cur[[rownames(E.cur)[k]]] <- fxn( lmer( eval(parse(text=par.list$form)), data=data3, REML=F, 
                                                  weights=W.cur[k,], 
                                                  control=par.list$control,na.action= par.list$na.action, 
                                                  start = list( theta = par.list$theta)))  
      which.gene <- c(which.gene, rownames(E.cur)[k])
      
    }, silent = T)
    
  }
  
  return(list(res.cur, which.gene))
  
}

stopCluster(cl)
# closeAllConnections()

# unpack results
res.var <-list()
for (i in 1:length(res)){
  res.var <- c(res.var, res[[i]][[1]])
}


```

```{r summary table, include = FALSE}



df.sum <- summarytools::dfSummary(df.meta.sub2, silent = T)

```


```{r consolidate findings}

# extract results
res.var2 <- extractVarPart2(res.var)

plt.var <- plotVarPart( res.var2 ) + 
  theme_miko() + 
  labs(title = "Variance Decomposition", subtitle = "Linear Mixed-Effects Model")  + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

if (print.inline){
  print(plt.var)
}

```


```{r # explore top genes}


df.var <- as.data.frame(res.var2)
df.var$gene <- rownames(df.var)

plt.rank.list <- list()

var.exp.threshold <- 0.001
label.top.n <- 30
for (i in 1:ncol(df.var)){
  
  colname.current <- colnames(df.var)[i]
  if (colname.current == "gene") next
  
  
  df.var.current <- df.var
  df.var.current <- df.var.current %>% dplyr::filter(get(colname.current) >= var.exp.threshold)
  df.var.current$rank <- rank(df.var.current[ ,colname.current])
  
  df.var.current2 <- df.var.current[ ,c("rank", colname.current, "gene")]
  colnames(df.var.current2) <- c("rank", "x", "gene")
  
  plt.rank.list[[colname.current]] <- df.var.current2 %>%
    ggplot(aes(x = rank, y = x*100)) + 
    geom_point() + 
    ggrepel::geom_text_repel(data = df.var.current2 %>% dplyr::top_n(label.top.n,x), 
                             aes(x = rank, y = x*100, label = gene)) + 
    xlab("Rank") + 
    ylab("Variance Explained (%)") + 
    theme_miko() + 
    labs(caption = paste0("Showing genes with >", var.exp.threshold*100, "% variance explained\ntop ", label.top.n, " labeled"),
         title = paste0("Covariate: ", colname.current), subtitle = "Linear mixed-effects model")
  
  if (print.inline){
    print(plt.rank.list[[colname.current]])    
  }
  
  df.var[ ,colname.current] <- signif(df.var[ ,colname.current], 3)
}

```


```{r central log}


if (exists("update.log")){
  do.update <- update.log
} else {
  do.update <- T
}

if (do.update){
  
  # update central log
  run.id <- NULL
  if (!exists("user")) user <- "guest"
  
  clog.update.success <- F
  try({
    run.id <-  updateCentralLog(Module = "M34", input.data = input.file, input.subset = NA, pdf.flag = save.pdf)
    clog.update.success <-  T
  }, silent = F)
  
  
  if (!(clog.update.success)){
    warning("Central log update was unsuccessful :(\n")
    run.id <- paste("M34_", user, "_r", paste0(format(Sys.time(), '%s')), sep = "", collapse = "")
  }
} else {
  clog.update.success <- F
  run.id <- paste("M34_", user, "_r", paste0(format(Sys.time(), '%s')), sep = "", collapse = "")
  save.pdf <- F
}

```


```{r setup output directories}

if (save.pdf){
  
  # output path
  if (!exists("data.path")) data.path = ""
  output.path <- paste0(data.path, "Module_Outputs/", paste0(run.id,"_",format(Sys.time(), '%d%m%y'), "/"))
  
  # create output directories
  dir.create(output.path)
  dir.create(paste0(output.path, "Tables/"))
  dir.create(paste0(output.path, "PDF/"))

} else {
  output.path <- ""
}

```

UMAP
===================================== 

Row {.tabset}
-------------------------------------

```{r umap plots}

out1.1 <-NULL

try({
    out1.1 <- lapply(seq_along(plt.umap.list), function(i) {
      
      s1 <- paste("plt.umap.list[[", i, "]]", sep = "")
      
      a1 <- knitr::knit_expand(text = sprintf("### %s\n", names(plt.umap.list)[i])) # tab header
      a2 <- knitr::knit_expand(text = sprintf("\n```{r %s,  fig.width = 7, fig.height = 7}", paste(i, "umap"))) 
      a3 <- knitr::knit_expand(text = sprintf("\n %s", s1))
      a4 <- knitr::knit_expand(text = "\n```\n") # end r chunk
      
      paste(a1, a2, a3, a4, collapse = '\n') # collapse together all lines with newline separator
      
    })
    
}, silent = T)

```
`r paste(knitr::knit(text = paste(out1.1, collapse = '\n')))`


```{r pdf umaps,include = FALSE}

for (i in 1:length(plt.umap.list)){
  try({
  plot.name <- paste0("M34_umap_", names(plt.umap.list)[i] ,".pdf")
  plot.name <- gsub(":", "_", plot.name)
  savePDF(file.name = paste0(output.path, "PDF/", plot.name), 
          plot.handle =  plt.umap.list[[i]], 
          fig.width = 7, fig.height = 7, save.flag = save.pdf)    
  }, silent = T)
}

```


Descriptives
===================================== 

### Summary Table

```{r descriptive statistics table}

df.sum

```



Variance Decomposition
===================================== 

Row {.tabset}
-------------------------------------

### Summary

```{r var decomp plot overview}
print(plt.var)
```
```{r var decomp plots}

out1.1 <-NULL

try({
    out1.1 <- lapply(seq_along(plt.rank.list), function(i) {
      
      s1 <- paste("plt.rank.list[[", i, "]]", sep = "")
      
      a1 <- knitr::knit_expand(text = sprintf("### %s\n", names(plt.rank.list)[i])) # tab header
      a2 <- knitr::knit_expand(text = sprintf("\n```{r %s,  fig.width = 7, fig.height = 7}", paste(i, "var decomp plo"))) 
      a3 <- knitr::knit_expand(text = sprintf("\n %s", s1))
      a4 <- knitr::knit_expand(text = "\n```\n") # end r chunk
      
      paste(a1, a2, a3, a4, collapse = '\n') # collapse together all lines with newline separator
      
    })
    
}, silent = T)

```
`r paste(knitr::knit(text = paste(out1.1, collapse = '\n')))`


```{r pdf var decomp plots,include = FALSE}

for (i in 1:length(plt.rank.list)){
  try({
  plot.name <- paste0("M34_varDecomp_", names(plt.rank.list)[i] ,".pdf")
  plot.name <- gsub(":", "_", plot.name)
  savePDF(file.name = paste0(output.path, "PDF/", plot.name), 
          plot.handle =  plt.rank.list[[i]], 
          fig.width = 7, fig.height = 7, save.flag = save.pdf)    
  }, silent = T)
}

```

Variance Decomposition Table
===================================== 
Proportion of variance explained by each covariate for each gene summarized in tabular format. 

```{r var decomp table}

flex.asDT(df.var)
```

```{r save decomp table}

if (save.pdf){
  try({
    write.csv(df.var, file = paste0(output.path, "Tables/", "variance_decoposition_table.csv"), 
              row.names = F)  
  }, silent = T)
}


```

```{r save results}

# Update analysis log
n.cells.analyzed <- ncol(so.query)
df.log <- addLogEntry("N Cells", n.cells.analyzed, df.log, "n.cells.analyzed")

# Run time
end.time <- proc.time()
elapsed.time <- round((end.time - start.time)[[3]], 2)
df.log <- addLogEntry("Run Time (s)", elapsed.time, df.log, "elapsed.time")

try({
  df.log <- addLogEntry("Run Identifier", run.id, df.log, "run.id")
  df.log <- addLogEntry("User", user, df.log, "user")
  df.log <- addLogEntry("Central Log Updated", clog.update.success, df.log, "clog.update.success")
}, silent = T)


df.log_Module_34 <- df.log

```

```{r ph10,  echo = FALSE, eval = TRUE}
out1 <- flex.multiTabLogs(module.logs)
```

`r paste(knitr::knit(text = paste(out1, collapse = '\n')))`

Log (Module 34)
===================================== 

```{r table.log_current}
knitr::kable(df.log_Module_34)
```

```{r save analysis log as csv}

if (save.pdf){
  try({
    write.csv(df.log_Module_34, file = paste0(output.path, "Tables/", "analysisLog.csv"), 
              row.names = F)  
  }, silent = T)
}


```

